# 🔍 LLM + RAG (Retrieval-Augmented Generation)

This module combines a **Language Model (LLM)** with **Retrieval-Augmented Generation (RAG)** to answer queries grounded in external knowledge. The system retrieves relevant context from a Vector Database (VectorDB) and supplies it to the LLM to produce informed and accurate responses.

## Test the module
```
python llm_rag_test.py
```